# éƒ¨ç½²ä¸è¿ç»´æ–‡æ¡£

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv2.0  
**æœ€åæ›´æ–°**ï¼š2026-01-23  
**å¯¹åº”è®¾è®¡æ–‡æ¡£**ï¼š[design.md](./design.md)  

---

> **æ–‡æ¡£å®šä½**ï¼šæœ¬æ–‡æ¡£æ˜¯ [design.md](./design.md) çš„è¡¥å……æ–‡æ¡£ï¼Œè¯¦ç»†å±•å¼€ç¬¬ 5 éƒ¨åˆ†"éƒ¨ç½²ä¸è¿ç»´"çš„å†…å®¹ã€‚

**ç›¸å…³æ–‡æ¡£**ï¼š
- [design.md](./design.md) - ä¸»è®¾è®¡æ–‡æ¡£
- [testing.md](./testing.md) - æµ‹è¯•ç­–ç•¥æ–‡æ¡£
- [service_evolution.md](./service_evolution.md) - æœåŠ¡åŒ–æ¼”è¿›è®¾è®¡ï¼ˆå®¹å™¨åŒ–éƒ¨ç½²ï¼‰

---

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº† msearch ç³»ç»Ÿçš„éƒ¨ç½²ã€è¿ç»´ã€ç›‘æ§å’Œæ•…éšœæ’æŸ¥ç­‰å†…å®¹ã€‚

**ç³»ç»Ÿæ¶æ„**ï¼šå•æœºéƒ¨ç½²ï¼Œæ‰€æœ‰æœåŠ¡åœ¨åŒä¸€å°æœºå™¨ä¸Šè¿è¡Œ  
**éƒ¨ç½²æ¨¡å¼**ï¼šæœ¬åœ°éƒ¨ç½²ï¼ˆæ¡Œé¢åº”ç”¨ï¼‰  
**è¿ç»´å¤æ‚åº¦**ï¼šä½ï¼ˆå•æœºè¿ç»´ï¼‰  

**å¿«é€Ÿå¼€å§‹**ï¼š  
- ä¸€é”®å®‰è£…ï¼š`bash scripts/install.sh`  
- ä¸€é”®å¯åŠ¨ï¼š`bash scripts/run.sh`  
- è¯¦ç»†æŒ‡å—ï¼š[QUICKSTART.md](../QUICKSTART.md)  

---

## ç¯å¢ƒå‡†å¤‡

### 2.1 ç¡¬ä»¶è¦æ±‚

**æœ€ä½é…ç½®**ï¼š
- **CPU**ï¼šIntel Core i5-8400 / AMD Ryzen 5 2600ï¼ˆ6æ ¸åŠä»¥ä¸Šï¼‰
- **å†…å­˜**ï¼š16GB RAM
- **GPU**ï¼šNVIDIA GPU with 8GB VRAMï¼ˆæ”¯æŒ CUDA 11.0+ï¼‰
- **å­˜å‚¨**ï¼š50GB å¯ç”¨ç©ºé—´ï¼ˆSSD æ¨èï¼‰
- **ç½‘ç»œ**ï¼šæ— ç‰¹æ®Šè¦æ±‚ï¼ˆé¦–æ¬¡å®‰è£…éœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰

**æ¨èé…ç½®**ï¼š
- **CPU**ï¼šIntel Core i7-10700K / AMD Ryzen 7 3700Xï¼ˆ8æ ¸åŠä»¥ä¸Šï¼‰
- **å†…å­˜**ï¼š32GB RAM
- **GPU**ï¼šNVIDIA RTX 3080 / RTX 4070ï¼ˆ10GB+ VRAMï¼‰
- **å­˜å‚¨**ï¼š200GB+ SSDï¼ˆæ¨è NVMe SSDï¼‰
- **ç½‘ç»œ**ï¼š100Mbps+ å¸¦å®½ï¼ˆç”¨äºæ¨¡å‹ä¸‹è½½ï¼‰

**ç¡¬ä»¶æ£€æµ‹**ï¼š
ç³»ç»Ÿåœ¨å®‰è£…æ—¶ä¼šè‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶é…ç½®ï¼Œæ ¹æ®ç¡¬ä»¶æƒ…å†µé€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚ç¡¬ä»¶æ£€æµ‹è„šæœ¬ä½äºï¼š`src/core/hardware/hardware_detector.py`

**ç¡¬ä»¶æ£€æµ‹é¡¹**ï¼š
- CPU æ ¸å¿ƒæ•°å’Œé¢‘ç‡
- å†…å­˜å¤§å°å’Œå¯ç”¨å†…å­˜
- GPU å‹å·ã€æ˜¾å­˜å¤§å°å’Œ CUDA æ”¯æŒæƒ…å†µ
- ç£ç›˜ç©ºé—´å’Œç±»å‹
- ç½‘ç»œå¸¦å®½ï¼ˆå¯é€‰ï¼‰

### 2.2 è½¯ä»¶è¦æ±‚

**æ“ä½œç³»ç»Ÿ**ï¼š
- **Windows**ï¼šWindows 10 64-bitï¼ˆ1909+ï¼‰æˆ– Windows 11
- **macOS**ï¼šmacOS 11.0+ï¼ˆBig Surï¼‰æˆ–æ›´é«˜ç‰ˆæœ¬
- **Linux**ï¼šUbuntu 20.04+ / Debian 11+ / CentOS 8+ï¼ˆ64ä½ï¼‰

**Python ç¯å¢ƒ**ï¼š
- **Python ç‰ˆæœ¬**ï¼š3.9 - 3.11ï¼ˆæ¨è 3.10ï¼‰
- **pip ç‰ˆæœ¬**ï¼š21.0+ï¼ˆæ¨è 23.0+ï¼‰
- **è™šæ‹Ÿç¯å¢ƒ**ï¼šæ¨èä½¿ç”¨ `venv` æˆ– `conda`

**ä¾èµ–åº“**ï¼š
```bash
# æ ¸å¿ƒä¾èµ–
pip install torch torchvision torchaudio  # PyTorchï¼ˆæ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹©ï¼‰
pip install infinity-emb  # Infinity æ¡†æ¶
pip install lancedb  # LanceDB å‘é‡æ•°æ®åº“
pip install sqlalchemy  # SQLite ORM
pip install fastapi uvicorn  # API æœåŠ¡å™¨
pip install python-multipart  # æ–‡ä»¶ä¸Šä¼ æ”¯æŒ
pip install watchdog  # æ–‡ä»¶ç›‘æ§
pip install pillow  # å›¾åƒå¤„ç†
pip install opencv-python  # è§†é¢‘å¤„ç†
pip install pydub  # éŸ³é¢‘å¤„ç†
pip install pyyaml  # YAML é…ç½®æ–‡ä»¶
pip install loguru  # æ—¥å¿—åº“
pip install pydantic  # æ•°æ®éªŒè¯
pip install tqdm  # è¿›åº¦æ¡

# å¯é€‰ä¾èµ–ï¼ˆç”¨äºç‰¹å®šåŠŸèƒ½ï¼‰
pip install ffmpeg-python  # FFmpeg é›†æˆï¼ˆè§†é¢‘å¤„ç†ï¼‰
pip install librosa  # éŸ³é¢‘åˆ†æ
pip install matplotlib  # å¯è§†åŒ–ï¼ˆæµ‹è¯•ç”¨ï¼‰
```

**FFmpeg å®‰è£…**ï¼š
è§†é¢‘å¤„ç†éœ€è¦ FFmpegï¼Œéœ€å•ç‹¬å®‰è£…ï¼š
- **Windows**ï¼šä» [FFmpeg å®˜ç½‘](https://ffmpeg.org/) ä¸‹è½½ï¼Œæ·»åŠ åˆ° PATH
- **macOS**ï¼š`brew install ffmpeg`
- **Linux**ï¼š`sudo apt install ffmpeg`ï¼ˆUbuntu/Debianï¼‰æˆ– `sudo dnf install ffmpeg`ï¼ˆCentOS/RHELï¼‰

### 2.3 CUDA ç¯å¢ƒé…ç½®

**CUDA ç‰ˆæœ¬**ï¼š11.0 - 12.0ï¼ˆæ¨è 11.8ï¼‰  
**cuDNN ç‰ˆæœ¬**ï¼š8.0+ï¼ˆä¸ CUDA ç‰ˆæœ¬åŒ¹é…ï¼‰  

**å®‰è£…æ­¥éª¤**ï¼š
1. ä¸‹è½½å¹¶å®‰è£… NVIDIA æ˜¾å¡é©±åŠ¨ï¼ˆç‰ˆæœ¬ 450.80.02+ï¼‰
2. ä¸‹è½½å¹¶å®‰è£… CUDA Toolkitï¼ˆæ¨è 11.8ï¼‰
3. ä¸‹è½½å¹¶å®‰è£… cuDNNï¼ˆä¸ CUDA ç‰ˆæœ¬åŒ¹é…ï¼‰
4. é…ç½®ç¯å¢ƒå˜é‡ï¼š
   ```bash
   # Linux/macOS
   export PATH=/usr/local/cuda-11.8/bin:$PATH
   export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH
   
   # Windowsï¼ˆç³»ç»Ÿç¯å¢ƒå˜é‡ï¼‰
   # PATH æ·»åŠ ï¼šC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\bin
   # PATH æ·»åŠ ï¼šC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\libnvvp
   ```

**éªŒè¯ CUDA å®‰è£…**ï¼š
```bash
# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# æ£€æŸ¥ GPU çŠ¶æ€
nvidia-smi

# éªŒè¯ PyTorch CUDA æ”¯æŒ
python -c "import torch; print(torch.cuda.is_available())"
```

---

## å®‰è£…æ­¥éª¤

### 3.1 å¿«é€Ÿå®‰è£…ï¼ˆæ¨èï¼‰

**ä¸€é”®å®‰è£…è„šæœ¬**ï¼š
```bash
# è¿è¡Œå®‰è£…è„šæœ¬ï¼ˆè‡ªåŠ¨å®Œæˆæ‰€æœ‰é…ç½®ï¼‰
bash scripts/install.sh
```

å®‰è£…è„šæœ¬ä¼šè‡ªåŠ¨å®Œæˆï¼š
1. âœ… æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆéœ€è¦3.8+ï¼‰
2. âœ… åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
3. âœ… å®‰è£…æ‰€æœ‰Pythonä¾èµ–
4. âœ… æ£€æµ‹ç¡¬ä»¶é…ç½®ï¼ˆCPU/GPU/å†…å­˜ï¼‰
5. âœ… ä¸‹è½½AIæ¨¡å‹ï¼ˆè‡ªåŠ¨ä½¿ç”¨å›½å†…é•œåƒï¼‰
6. âœ… é…ç½®ç¦»çº¿æ¨¡å¼
7. âœ… è¿è¡Œå•å…ƒæµ‹è¯•

**å®‰è£…å®Œæˆå**ï¼š
```bash
# ä¸€é”®å¯åŠ¨åº”ç”¨
bash scripts/run.sh
```

### 3.2 æ‰‹åŠ¨å®‰è£…

**å…‹éš†ä»£ç ä»“åº“**ï¼š
```bash
git clone https://github.com/your-username/msearch.git
cd msearch
```

**åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**ï¼š
```bash
# ä½¿ç”¨ venv
python -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Linux/macOS
source venv/bin/activate
# Windows
venv\Scripts\activate
```

**å®‰è£…ä¾èµ–**ï¼š
```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å®‰è£…å¯é€‰ä¾èµ–ï¼ˆç”¨äºè§†é¢‘å¤„ç†ç­‰åŠŸèƒ½ï¼‰
pip install -r requirements/optional.txt
```

**ä¸‹è½½æ¨¡å‹**ï¼š
```bash
# æ–¹æ³• 1ï¼šé€šè¿‡å®‰è£…è„šæœ¬è‡ªåŠ¨ä¸‹è½½
python scripts/setup_models.py setup

# æ–¹æ³• 2ï¼šæ‰‹åŠ¨ä¸‹è½½ï¼ˆä½¿ç”¨å›½å†…é•œåƒï¼‰
export HF_ENDPOINT=https://hf-mirror.com
python -m huggingface-cli download \
    --resume-download \
    --local-dir-use-symlinks False \
    OFA-Sys/chinese-clip-vit-base-patch16 \
    --local-dir data/models/chinese-clip-vit-base-patch16

python -m huggingface-cli download \
    --resume-download \
    --local-dir-use-symlinks False \
    laion/clap-htsat-unfused \
    --local-dir data/models/clap-htsat-unfused
```

**é…ç½®æ–‡ä»¶**ï¼š
```bash
# å¤åˆ¶é…ç½®æ–‡ä»¶æ¨¡æ¿
cp config/config.yml.example config/config.yml

# ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼ˆæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
```

### 3.4 Docker éƒ¨ç½²ï¼ˆå¯é€‰ï¼‰

**æ„å»º Docker é•œåƒ**ï¼š
```bash
docker build -t msearch:latest .
```

**è¿è¡Œ Docker å®¹å™¨**ï¼š
```bash
docker run -d \
  --name msearch \
  --gpus all \
  -p 8000:8000 \
  -p 5173:5173 \
  -v /path/to/data:/app/data \
  -v /path/to/models:/app/data/models \
  -v /path/to/monitor:/data/monitor \
  --restart unless-stopped \
  msearch:latest
```

**Docker Compose**ï¼š
```yaml
# docker-compose.yml
version: '3.8'

services:
  msearch:
    image: msearch:latest
    container_name: msearch
    restart: unless-stopped
    ports:
      - "8000:8000"  # API ç«¯å£
      - "5173:5173"  # Web UI ç«¯å£
    volumes:
      - ./data:/app/data
      - ./data/models:/app/data/models
      - /path/to/monitor:/data/monitor
    environment:
      - PYTHONUNBUFFERED=1
      - MSEARCH_CONFIG=/app/config/config.yml
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

**å¯åŠ¨å‘½ä»¤**ï¼š
```bash
docker-compose up -d
```

### 3.3 å®‰è£…éªŒè¯

**æ£€æŸ¥ç¯å¢ƒ**ï¼š
```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬
python --version

# æ£€æŸ¥ä¾èµ–ç‰ˆæœ¬
pip list | grep -E "torch|infinity|lancedb|fastapi"

# æ£€æŸ¥ GPU å¯ç”¨æ€§
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU count: {torch.cuda.device_count()}'); print(f'GPU name: {torch.cuda.get_device_name(0)}')"

# æ£€æŸ¥ FFmpeg
ffmpeg -version
```

**æ£€æŸ¥æ¨¡å‹**ï¼š
```bash
# æ£€æŸ¥æ¨¡å‹å®Œæ•´æ€§
python scripts/setup_models.py check

# é¢„æœŸè¾“å‡ºï¼š
# âœ“ chinese-clip-vit-base-patch16: 1436.78 MB (å®Œæ•´)
# âœ“ clap-htsat-unfused: 589.28 MB (å®Œæ•´)
```

**è¿è¡Œæµ‹è¯•**ï¼š
```bash
# è¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/unit/ -v

# è¿è¡Œé›†æˆæµ‹è¯•
pytest tests/integration/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/unit/test_config.py -v
pytest tests/unit/test_embedding_engine.py -v
```

**å¯åŠ¨æœåŠ¡**ï¼š
```bash
# å¯åŠ¨ API æœåŠ¡å™¨
python src/api_server.py

# æˆ–ä½¿ç”¨å¯åŠ¨è„šæœ¬
bash scripts/run.sh
```

**éªŒè¯æœåŠ¡**ï¼š
```bash
# æ£€æŸ¥ API æœåŠ¡æ˜¯å¦æ­£å¸¸
curl http://localhost:8000/health

# æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯
curl http://localhost:8000/api/v1/system/info

# æ£€æŸ¥æ¨¡å‹ä¿¡æ¯
curl http://localhost:8000/api/v1/models/info
```

---

## å¯åŠ¨ä¸åœæ­¢

### 4.1 å¿«é€Ÿå¯åŠ¨ï¼ˆæ¨èï¼‰

**ä¸€é”®å¯åŠ¨è„šæœ¬**ï¼š
```bash
# å¯åŠ¨å®Œæ•´åº”ç”¨ï¼ˆAPIæœåŠ¡ + WebUIï¼‰
bash scripts/run.sh
```

å¯åŠ¨åï¼š
- ğŸŒ æµè§ˆå™¨ä¼šè‡ªåŠ¨æ‰“å¼€ WebUI: http://localhost:8080
- ğŸ“¡ APIæœåŠ¡è¿è¡Œåœ¨: http://localhost:8000
- ğŸ“š APIæ–‡æ¡£: http://localhost:8000/docs

### 4.2 æ‰‹åŠ¨å¯åŠ¨

**å¯åŠ¨é¡ºåº**ï¼š
1. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
2. è®¾ç½®ç¦»çº¿ç¯å¢ƒå˜é‡
3. å¯åŠ¨APIæœåŠ¡
4. å¯åŠ¨WebUIï¼ˆå¯é€‰ï¼‰

**å¯åŠ¨å‘½ä»¤**ï¼š
```bash
# æ–¹å¼ 1ï¼šå¯åŠ¨å®Œæ•´æœåŠ¡ï¼ˆAPI + WebUIï¼‰
bash scripts/run.sh

# æ–¹å¼ 2ï¼šä»…å¯åŠ¨ API æœåŠ¡å™¨
source venv/bin/activate
export HF_HOME="data/models"
export TRANSFORMERS_OFFLINE=1
export HF_DATASETS_OFFLINE=1
export HF_HUB_OFFLINE=1
python src/api_server.py

# æ–¹å¼ 3ï¼šä»…å¯åŠ¨ PySide6 æ¡Œé¢UI
source venv/bin/activate
python src/ui/ui_launcher.py

# æ–¹å¼ 4ï¼šä½¿ç”¨ uvicornï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
source venv/bin/activate
uvicorn src.api_server:app --host 0.0.0.0 --port 8000 --workers 1 --log-level info

# æ–¹å¼ 5ï¼šä½¿ç”¨ nohupï¼ˆåå°è¿è¡Œï¼‰
source venv/bin/activate
nohup python src/api_server.py > /dev/null 2>&1 &
```

### 4.3 åœæ­¢æœåŠ¡

**åœæ­¢å‘½ä»¤**ï¼š
```bash
# æ–¹å¼ 1ï¼šCtrl+Cï¼ˆå‰å°è¿è¡Œï¼‰
Ctrl+C

# æ–¹å¼ 2ï¼škill å‘½ä»¤ï¼ˆåå°è¿è¡Œï¼‰
ps aux | grep "python src/api_server.py" | grep -v grep | awk '{print $2}' | xargs kill

# æ–¹å¼ 3ï¼šåœæ­¢æ‰€æœ‰ç›¸å…³è¿›ç¨‹
pkill -f "python src/api_server.py"
pkill -f "python -m http.server"  # WebUI

# æ–¹å¼ 4ï¼šä½¿ç”¨è„šæœ¬åœæ­¢ï¼ˆå¦‚æœæœ‰ï¼‰
bash scripts/stop.sh
```

**åœæ­¢æ—¥å¿—**ï¼š
```
2026-01-19 18:00:00 | INFO | api_server:shutdown:125 | Received shutdown signal
2026-01-19 18:00:00 | INFO | api_server:shutdown:128 | Stopping API server
2026-01-19 18:00:00 | INFO | file_monitor:stop:42 | Stopping file monitor
2026-01-19 18:00:00 | INFO | task_manager:stop:55 | Stopping task manager
2026-01-19 18:00:05 | INFO | task_manager:stop:62 | Task manager stopped (4 tasks completed, 0 pending)
2026-01-19 18:00:05 | INFO | embedding_engine:unload_model:92 | Unloading audio model
2026-01-19 18:00:05 | INFO | embedding_engine:unload_model:95 | Unloading image/video model
2026-01-19 18:00:05 | INFO | vector_store:close:45 | Closing LanceDB vector store
2026-01-19 18:00:05 | INFO | database_manager:close:45 | Closing SQLite database
2026-01-19 18:00:05 | INFO | api_server:shutdown:142 | msearch stopped successfully
```

---

## æ¨¡å‹ç®¡ç†

### æ¨¡å‹ä¸‹è½½

**è‡ªåŠ¨ä¸‹è½½ï¼ˆæ¨èï¼‰**ï¼š
```bash
# è¿è¡Œå®‰è£…è„šæœ¬æ—¶è‡ªåŠ¨ä¸‹è½½
bash scripts/install.sh
```

**æ‰‹åŠ¨ä¸‹è½½**ï¼š
```bash
# æ£€æŸ¥æ¨¡å‹çŠ¶æ€
python scripts/setup_models.py check

# ä¸‹è½½æ¨¡å‹ï¼ˆè·³è¿‡å·²å­˜åœ¨çš„ï¼‰
python scripts/setup_models.py setup

# å¼ºåˆ¶é‡æ–°ä¸‹è½½
python scripts/setup_models.py setup --force

# æ¸…é™¤æ¨¡å‹
python scripts/setup_models.py clear
```

**ä½¿ç”¨å›½å†…é•œåƒ**ï¼š
```bash
# è®¾ç½®HuggingFaceé•œåƒ
export HF_ENDPOINT=https://hf-mirror.com

# ä¸‹è½½æ¨¡å‹
python -m huggingface-cli download \
    --resume-download \
    --local-dir-use-symlinks False \
    OFA-Sys/chinese-clip-vit-base-patch16 \
    --local-dir data/models/chinese-clip-vit-base-patch16
```

### æ¨¡å‹æ£€æŸ¥

**æ£€æŸ¥æ¨¡å‹å®Œæ•´æ€§**ï¼š
```bash
python scripts/setup_models.py check
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
æ£€æŸ¥æ¨¡å‹çŠ¶æ€...
âœ“ chinese-clip-vit-base-patch16: 1436.78 MB (å®Œæ•´)
âœ“ clap-htsat-unfused: 589.28 MB (å®Œæ•´)

æ‰€æœ‰æ¨¡å‹å®Œæ•´ï¼Œæ— éœ€ä¸‹è½½
```

### æ¨¡å‹é…ç½®

**æ¨¡å‹é€‰æ‹©**ï¼š
```yaml
# config/config.yml
models:
  image_video_model:
    model_name: "OFA-Sys/chinese-clip-vit-base-patch16"  # åŸºç¡€æ¨¡å‹
    # model_name: "OFA-Sys/chinese-clip-vit-large-patch14-336px"  # é«˜ç²¾åº¦æ¨¡å‹
    # model_name: "SauerkrautLM/ColQwen3-1.7b-Turbo-v0.1"  # é«˜æ€§èƒ½æ¨¡å‹
    model_path: "data/models/chinese-clip-vit-base-patch16"
    embedding_dim: 512
    device: "cuda"  # cuda æˆ– cpu
    precision: "float16"  # float16 æˆ– float32
    batch_size: 16
```

**ç¡¬ä»¶è‡ªé€‚åº”**ï¼š
- ä½é…ï¼ˆCPU/4GBå†…å­˜ï¼‰ï¼šä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼ˆ512ç»´ï¼‰
- ä¸­é…ï¼ˆGPU/8GBå†…å­˜ï¼‰ï¼šä½¿ç”¨é«˜ç²¾åº¦æ¨¡å‹ï¼ˆ1024ç»´ï¼‰
- é«˜é…ï¼ˆGPU/16GB+å†…å­˜ï¼‰ï¼šä½¿ç”¨é«˜æ€§èƒ½æ¨¡å‹ï¼ˆ2048ç»´ï¼‰

---

## ç›‘æ§ä¸æ—¥å¿—

### 5.1 ç³»ç»Ÿç›‘æ§

**ç›‘æ§æŒ‡æ ‡**ï¼š
- **ç³»ç»Ÿèµ„æº**ï¼šCPUã€å†…å­˜ã€GPUã€ç£ç›˜ã€ç½‘ç»œä½¿ç”¨æƒ…å†µ
- **æœåŠ¡çŠ¶æ€**ï¼šAPI æœåŠ¡å™¨ã€ä»»åŠ¡è°ƒåº¦å™¨ã€æ–‡ä»¶ç›‘æ§å™¨çŠ¶æ€
- **æ¨¡å‹çŠ¶æ€**ï¼šæ¨¡å‹åŠ è½½çŠ¶æ€ã€æ¨ç†é€Ÿåº¦ã€æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
- **æ•°æ®åº“çŠ¶æ€**ï¼šSQLite å’Œ LanceDB è¿æ¥æ•°ã€æŸ¥è¯¢æ€§èƒ½
- **ä»»åŠ¡çŠ¶æ€**ï¼šä»»åŠ¡é˜Ÿåˆ—é•¿åº¦ã€æ‰§è¡Œé€Ÿåº¦ã€æˆåŠŸç‡
- **æ–‡ä»¶çŠ¶æ€**ï¼šç›‘æ§ç›®å½•æ•°é‡ã€æ–‡ä»¶æ•°é‡ã€ç´¢å¼•è¿›åº¦

**ç›‘æ§æ¥å£**ï¼š
```bash
# ç³»ç»Ÿä¿¡æ¯
curl http://localhost:8000/api/v1/system/info

# æ¨¡å‹ä¿¡æ¯
curl http://localhost:8000/api/v1/models/info

# æ•°æ®åº“ç»Ÿè®¡
curl http://localhost:8000/api/v1/database/stats

# ä»»åŠ¡ç»Ÿè®¡
curl http://localhost:8000/api/v1/tasks/stats

# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health
```

**ç›‘æ§è„šæœ¬**ï¼š
```bash
# å®æ—¶ç›‘æ§ GPU ä½¿ç”¨æƒ…å†µ
watch -n 1 nvidia-smi

# å®æ—¶ç›‘æ§ç³»ç»Ÿèµ„æº
htop

# å®æ—¶ç›‘æ§æ—¥å¿—
tail -f data/logs/msearch.log

# ç›‘æ§ä»»åŠ¡é˜Ÿåˆ—
watch -n 5 "curl -s http://localhost:8000/api/v1/tasks/stats | jq '.data.running'"
```

### 5.2 æ—¥å¿—ç®¡ç†

**æ—¥å¿—é…ç½®**ï¼š
```yaml
# config/config.yml
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{function}:{line} | {message}"
  rotation: "1 day"  # æ—¥å¿—è½®è½¬ï¼ˆæ¯å¤©ï¼‰
  retention: "7 days"  # æ—¥å¿—ä¿ç•™ï¼ˆ7å¤©ï¼‰
  compression: "zip"  # å‹ç¼©æ ¼å¼
```

**æ—¥å¿—ä½ç½®**ï¼š
- **ä¸»æ—¥å¿—**ï¼š`data/logs/msearch.log`
- **é”™è¯¯æ—¥å¿—**ï¼š`data/logs/msearch.error.log`
- **è®¿é—®æ—¥å¿—**ï¼š`data/logs/msearch.access.log`ï¼ˆAPI è¯·æ±‚æ—¥å¿—ï¼‰
- **è½®è½¬æ—¥å¿—**ï¼š`data/logs/msearch.log.2026-01-19_10-00-00.zip`

**æ—¥å¿—æ ¼å¼**ï¼š
```
2026-01-19 10:00:00 | INFO | msearch:main:12 | Starting msearch v2.0.0
2026-01-19 10:00:00 | DEBUG | config:load_config:45 | Loading configuration from config/config.yml
2026-01-19 10:00:00 | INFO | embedding_engine:load_model:65 | Loading image/video model: [é…ç½®é©±åŠ¨æ¨¡å‹]
2026-01-19 10:00:15 | INFO | embedding_engine:load_model:72 | Image/video model loaded successfully
2026-01-19 10:00:23 | INFO | main:start_api:112 | Starting API server on http://0.0.0.0:8000
2026-01-19 10:00:25 | WARNING | file_monitor:on_created:78 | File too large, skipping: /path/to/large/file.mp4
2026-01-19 10:00:30 | ERROR | task_executor:execute:125 | Task failed: file_embed_video (file_id: file_123456)
```

**æ—¥å¿—åˆ†æ**ï¼š
```bash
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
grep "ERROR" data/logs/msearch.log

# æŸ¥çœ‹è­¦å‘Šæ—¥å¿—
grep "WARNING" data/logs/msearch.log

# æŸ¥çœ‹ç‰¹å®šæ¨¡å—æ—¥å¿—
grep "embedding_engine" data/logs/msearch.log

# æŸ¥çœ‹ç‰¹å®šæ—¶é—´æ®µæ—¥å¿—
sed -n '/2026-01-19 10:00:00/,/2026-01-19 11:00:00/p' data/logs/msearch.log

# ç»Ÿè®¡é”™è¯¯æ•°é‡
grep -c "ERROR" data/logs/msearch.log

# ç»Ÿè®¡ä»»åŠ¡å¤±è´¥æ•°é‡
grep -c "Task failed" data/logs/msearch.log
```

---

## å¤‡ä»½ä¸æ¢å¤

### 6.1 æ•°æ®å¤‡ä»½

**å¤‡ä»½å†…å®¹**ï¼š
- **å‘é‡æ•°æ®åº“**ï¼š`data/database/lancedb/`
- **å…ƒæ•°æ®æ•°æ®åº“**ï¼š`data/database/sqlite/msearch.db`
- **é…ç½®æ–‡ä»¶**ï¼š`config/config.yml`
- **æ¨¡å‹æ–‡ä»¶**ï¼š`data/models/`ï¼ˆå¯é€‰ï¼Œå¯é‡æ–°ä¸‹è½½ï¼‰
- **æ—¥å¿—æ–‡ä»¶**ï¼š`data/logs/`ï¼ˆå¯é€‰ï¼‰

**å¤‡ä»½è„šæœ¬**ï¼š
```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="/path/to/backup"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="msearch_backup_${TIMESTAMP}"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p ${BACKUP_DIR}

# æ‰“åŒ…æ•°æ®
tar -czf ${BACKUP_DIR}/${BACKUP_NAME}.tar.gz \
  --exclude="*.tmp" \
  --exclude="*.temp" \
  --exclude="*.lock" \
  data/database/ \
  config/config.yml

# å¯é€‰ï¼šå¤‡ä»½æ¨¡å‹
# tar -czf ${BACKUP_DIR}/${BACKUP_NAME}_models.tar.gz data/models/

echo "Backup completed: ${BACKUP_DIR}/${BACKUP_NAME}.tar.gz"
```

**è‡ªåŠ¨å¤‡ä»½**ï¼š
```bash
# é…ç½® crontabï¼ˆæ¯å¤©å‡Œæ™¨ 2 ç‚¹å¤‡ä»½ï¼‰
0 2 * * * /path/to/msearch/scripts/backup.sh >> /var/log/msearch_backup.log 2>&1
```

### 6.2 æ•°æ®æ¢å¤

**æ¢å¤æ­¥éª¤**ï¼š
```bash
# 1. åœæ­¢æœåŠ¡
python src/api/main.py stop

# 2. å¤‡ä»½å½“å‰æ•°æ®ï¼ˆå¯é€‰ï¼‰
tar -czf data_backup_before_restore.tar.gz data/

# 3. è§£å‹å¤‡ä»½æ–‡ä»¶
tar -xzf /path/to/backup/msearch_backup_20260119_020000.tar.gz -C /

# 4. éªŒè¯æ•°æ®
ls -la data/database/sqlite/
ls -la data/database/lancedb/

# 5. å¯åŠ¨æœåŠ¡
python src/api/main.py start
```

**æ¢å¤éªŒè¯**ï¼š
```bash
# æ£€æŸ¥æ•°æ®åº“è¿æ¥
curl http://localhost:8000/api/v1/database/stats

# æ£€æŸ¥æ–‡ä»¶æ•°é‡
curl http://localhost:8000/api/v1/files?page=1&page_size=1

# æ‰§è¡Œæµ‹è¯•æ£€ç´¢
curl -X POST http://localhost:8000/api/v1/search \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "top_k": 5}'
```

---

## æ€§èƒ½ä¼˜åŒ–

### 7.1 ç³»ç»Ÿä¼˜åŒ–

**Linux ç³»ç»Ÿä¼˜åŒ–**ï¼š
```bash
# 1. å¢åŠ æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
echo "* soft nofile 65536" >> /etc/security/limits.conf
echo "* hard nofile 65536" >> /etc/security/limits.conf

# 2. å¢åŠ å†…å­˜æ˜ å°„é™åˆ¶
echo "vm.max_map_count=262144" >> /etc/sysctl.conf
sysctl -p

# 3. ä¼˜åŒ–ç£ç›˜ I/O
echo "vm.dirty_ratio=10" >> /etc/sysctl.conf
echo "vm.dirty_background_ratio=5" >> /etc/sysctl.conf
sysctl -p

# 4. ç¦ç”¨ swapï¼ˆå¦‚æœæœ‰è¶³å¤Ÿå†…å­˜ï¼‰
sudo swapoff -a
```

**Windows ç³»ç»Ÿä¼˜åŒ–**ï¼š
- å…³é—­è™šæ‹Ÿå†…å­˜ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿå†…å­˜ï¼‰
- ä¼˜åŒ– SSDï¼ˆç¦ç”¨ç£ç›˜ç¢ç‰‡æ•´ç†ï¼‰
- å…³é—­ä¸å¿…è¦çš„åå°ç¨‹åº
- è°ƒæ•´ç”µæºè®¡åˆ’ä¸ºé«˜æ€§èƒ½

**macOS ç³»ç»Ÿä¼˜åŒ–**ï¼š
- å…³é—­ Spotlight ç´¢å¼•ï¼ˆåœ¨ç›‘æ§ç›®å½•ï¼‰
- ç¦ç”¨ Time Machine è‡ªåŠ¨å¤‡ä»½ï¼ˆåœ¨ç›‘æ§ç›®å½•ï¼‰
- è°ƒæ•´ç”µæºè®¾ç½®ä¸ºé«˜æ€§èƒ½

### 7.2 åº”ç”¨ä¼˜åŒ–

**æ¨¡å‹ä¼˜åŒ–**ï¼š
```yaml
# config/config.yml
models:
  [é…ç½®é©±åŠ¨æ¨¡å‹]:
    batch_size: 16  # æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´ï¼ˆ8-32ï¼‰
    precision: "float16"  # ä½¿ç”¨æ··åˆç²¾åº¦
    device: "cuda"  # ä½¿ç”¨ GPU
  
  [é…ç½®é©±åŠ¨æ¨¡å‹]:
    batch_size: 8  # æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´ï¼ˆ4-16ï¼‰
    precision: "float16"
    device: "cuda"
```

**è§†é¢‘å¤„ç†ä¼˜åŒ–**ï¼š
```yaml
# config/config.yml
performance:
  video_processing:
    frame_interval: 10  # å¢åŠ é‡‡æ ·é—´éš”ï¼ˆå‡å°‘å¤„ç†æ—¶é—´ï¼‰
    target_fps: 2  # é™ä½ç›®æ ‡å¸§ç‡
    max_segments_per_video: 50  # å‡å°‘æœ€å¤§åˆ†æ®µæ•°
    scene_threshold: 0.3  # è°ƒæ•´åœºæ™¯å˜åŒ–é˜ˆå€¼
```

**æ•°æ®åº“ä¼˜åŒ–**ï¼š
```yaml
# config/config.yml
vector_store:
  index_type: "ivf"  # ä½¿ç”¨ IVF ç´¢å¼•ï¼ˆé€‚åˆå¤§æ•°æ®é‡ï¼‰
  nlist: 1024  # æ ¹æ®æ•°æ®é‡è°ƒæ•´ï¼ˆ512-4096ï¼‰

database:
  pool_size: 5  # è¿æ¥æ± å¤§å°
  max_overflow: 10
```

**ä»»åŠ¡è°ƒåº¦ä¼˜åŒ–**ï¼š
```yaml
# config/config.yml
task_scheduler:
  max_workers: 4  # æ ¹æ® CPU æ ¸å¿ƒæ•°è°ƒæ•´ï¼ˆ2-8ï¼‰
  queue_size: 1000
  retry_count: 3
  retry_delay: 5
```

### 7.3 æ€§èƒ½ç›‘æ§

**æ€§èƒ½æŒ‡æ ‡**ï¼š
```bash
# æ¨¡å‹æ¨ç†é€Ÿåº¦
# å›¾åƒï¼š< 100ms/å¼ 
# è§†é¢‘ï¼š< 500ms/ç§’è§†é¢‘
# éŸ³é¢‘ï¼š< 1000ms/æ®µéŸ³é¢‘

# æ£€ç´¢é€Ÿåº¦
# æ–‡æœ¬æ£€ç´¢ï¼š< 500ms
# å›¾åƒæ£€ç´¢ï¼š< 1000ms
# éŸ³é¢‘æ£€ç´¢ï¼š< 1500ms

# ç´¢å¼•é€Ÿåº¦
# å›¾åƒï¼š< 1 ç§’/å¼ 
# è§†é¢‘ï¼š< 30 ç§’/åˆ†é’Ÿè§†é¢‘
# éŸ³é¢‘ï¼š< 10 ç§’/åˆ†é’ŸéŸ³é¢‘

# å†…å­˜ä½¿ç”¨
# æ¨¡å‹åŠ è½½ï¼š< 10GB
# è¿è¡Œæ—¶ï¼š< 16GB

# GPU æ˜¾å­˜ä½¿ç”¨
# æ¨¡å‹ï¼š< 8GB
# è¿è¡Œæ—¶ï¼š< 10GB
```

**æ€§èƒ½æµ‹è¯•**ï¼š
```bash
# è¿è¡ŒåŸºå‡†æµ‹è¯•
pytest tests/benchmark/ -v

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
python scripts/run_benchmark.py --output data/benchmark/report.json

# æŸ¥çœ‹æ€§èƒ½æŠ¥å‘Š
cat data/benchmark/report.json | jq '.performance'
```

---

## æ•…éšœæ’æŸ¥

### 8.1 å¸¸è§é—®é¢˜

**é—®é¢˜ 1ï¼šæ¨¡å‹åŠ è½½å¤±è´¥**
```
ERROR | embedding_engine:load_model:75 | Failed to load model: [é…ç½®é©±åŠ¨æ¨¡å‹]
Error: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- é™ä½ batch_sizeï¼ˆé…ç½®æ–‡ä»¶ï¼‰
- ä½¿ç”¨ float32 ç²¾åº¦ï¼ˆé…ç½®æ–‡ä»¶ï¼‰
- ä½¿ç”¨ CPU æ¨ç†ï¼ˆdevice: "cpu"ï¼‰
- å…³é—­å…¶ä»–å ç”¨ GPU çš„ç¨‹åº
- å¢åŠ  GPU æ˜¾å­˜ï¼ˆç¡¬ä»¶å‡çº§ï¼‰

**é—®é¢˜ 2ï¼šCUDA ä¸å¯ç”¨**
```
WARNING | embedding_engine:load_model:70 | CUDA not available, falling back to CPU
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥ NVIDIA é©±åŠ¨æ˜¯å¦å®‰è£…
- æ£€æŸ¥ CUDA æ˜¯å¦å®‰è£…
- æ£€æŸ¥ PyTorch æ˜¯å¦æ”¯æŒ CUDA
- éªŒè¯å‘½ä»¤ï¼š`python -c "import torch; print(torch.cuda.is_available())"`

**é—®é¢˜ 3ï¼šæ–‡ä»¶ç›‘æ§ä¸å·¥ä½œ**
```
WARNING | file_monitor:on_created:78 | File not found: /path/to/file.jpg
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- æ£€æŸ¥æ–‡ä»¶æƒé™
- æ£€æŸ¥ ignore_patterns é…ç½®
- é‡å¯æ–‡ä»¶ç›‘æ§å™¨

**é—®é¢˜ 4ï¼šæ£€ç´¢ç»“æœä¸ºç©º**
```json
{
    "code": 0,
    "message": "success",
    "data": {
        "query": "test",
        "total": 0,
        "results": []
    }
}
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥æ˜¯å¦æœ‰å·²ç´¢å¼•çš„æ–‡ä»¶
- æ£€æŸ¥æ£€ç´¢å‚æ•°æ˜¯å¦æ­£ç¡®
- æ£€æŸ¥ç›¸ä¼¼åº¦é˜ˆå€¼æ˜¯å¦è¿‡é«˜
- æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½æˆåŠŸ
- é‡æ–°ç´¢å¼•æ–‡ä»¶

**é—®é¢˜ 5ï¼šAPI æœåŠ¡å™¨æ— æ³•å¯åŠ¨**
```
ERROR | main:start_api:115 | Failed to start API server
Error: [Errno 98] Address already in use
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼š`netstat -tlnp | grep 8000`
- æ€æ­»å ç”¨ç«¯å£çš„è¿›ç¨‹ï¼š`kill -9 <pid>`
- ä¿®æ”¹ API ç«¯å£ï¼ˆé…ç½®æ–‡ä»¶ï¼‰

**é—®é¢˜ 6ï¼šæ•°æ®åº“è¿æ¥å¤±è´¥**
```
ERROR | database_manager:init_database:35 | Failed to initialize database
Error: unable to open database file
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥æ•°æ®åº“ç›®å½•æ˜¯å¦å­˜åœ¨ï¼š`ls -la data/database/sqlite/`
- æ£€æŸ¥ç›®å½•æƒé™ï¼š`chmod -R 755 data/database/`
- æ£€æŸ¥ç£ç›˜ç©ºé—´ï¼š`df -h`
- é‡æ–°åˆå§‹åŒ–æ•°æ®åº“ï¼š`python scripts/init_database.py`

### 8.2 æ—¥å¿—åˆ†æ

**é”™è¯¯æ—¥å¿—æ¨¡å¼**ï¼š
```bash
# æŸ¥æ‰¾æ‰€æœ‰é”™è¯¯
grep "ERROR" data/logs/msearch.log | head -20

# æŸ¥æ‰¾ç‰¹å®šé”™è¯¯
grep "CUDA out of memory" data/logs/msearch.log
grep "Failed to load model" data/logs/msearch.log
grep "Task failed" data/logs/msearch.log

# ç»Ÿè®¡é”™è¯¯ç±»å‹
grep "ERROR" data/logs/msearch.log | awk -F'|' '{print $4}' | sort | uniq -c | sort -rn

# æŸ¥çœ‹æœ€è¿‘çš„é”™è¯¯
tail -100 data/logs/msearch.log | grep "ERROR"
```

**è­¦å‘Šæ—¥å¿—æ¨¡å¼**ï¼š
```bash
# æŸ¥æ‰¾æ‰€æœ‰è­¦å‘Š
grep "WARNING" data/logs/msearch.log | head -20

# æŸ¥æ‰¾ç‰¹å®šè­¦å‘Š
grep "CUDA not available" data/logs/msearch.log
grep "File not found" data/logs/msearch.log
```

### 8.3 è¯Šæ–­å·¥å…·

**ç³»ç»Ÿè¯Šæ–­**ï¼š
```bash
# æ£€æŸ¥ç³»ç»Ÿèµ„æº
htop
nvidia-smi
df -h
free -h

# æ£€æŸ¥è¿›ç¨‹
ps aux | grep msearch
ps aux | grep python

# æ£€æŸ¥ç«¯å£
netstat -tlnp | grep 8000
netstat -tlnp | grep 5173

# æ£€æŸ¥æ–‡ä»¶æè¿°ç¬¦
lsof -p <pid> | wc -l
```

**åº”ç”¨è¯Šæ–­**ï¼š
```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# ç³»ç»Ÿä¿¡æ¯
curl http://localhost:8000/api/v1/system/info

# æ¨¡å‹ä¿¡æ¯
curl http://localhost:8000/api/v1/models/info

# æ•°æ®åº“ç»Ÿè®¡
curl http://localhost:8000/api/v1/database/stats

# ä»»åŠ¡ç»Ÿè®¡
curl http://localhost:8000/api/v1/tasks/stats

# æµ‹è¯•æ£€ç´¢
curl -X POST http://localhost:8000/api/v1/search \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "top_k": 5}'
```

### 8.4 æ¢å¤æµç¨‹

**æ¢å¤æ­¥éª¤**ï¼š
1. **æ”¶é›†ä¿¡æ¯**ï¼š
   - é”™è¯¯æ—¥å¿—
   - ç³»ç»ŸçŠ¶æ€ï¼ˆCPUã€å†…å­˜ã€GPUã€ç£ç›˜ï¼‰
   - é…ç½®æ–‡ä»¶
   - æœ€è¿‘çš„æ“ä½œ

2. **å®šä½é—®é¢˜**ï¼š
   - æ ¹æ®é”™è¯¯ä¿¡æ¯å®šä½é—®é¢˜
   - æŸ¥çœ‹ç›¸å…³æ—¥å¿—
   - ä½¿ç”¨è¯Šæ–­å·¥å…·

3. **å°è¯•ä¿®å¤**ï¼š
   - æ ¹æ®å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆå°è¯•ä¿®å¤
   - ä¿®æ”¹é…ç½®æ–‡ä»¶
   - é‡å¯æœåŠ¡

4. **éªŒè¯ä¿®å¤**ï¼š
   - è¿è¡Œæµ‹è¯•
   - æ£€æŸ¥æ—¥å¿—
   - éªŒè¯åŠŸèƒ½

5. **è®°å½•é—®é¢˜**ï¼š
   - è®°å½•é—®é¢˜æè¿°
   - è®°å½•è§£å†³æ–¹æ¡ˆ
   - è®°å½•é¢„é˜²æªæ–½

---

## å‡çº§ä¸ç»´æŠ¤

### 9.1 ç‰ˆæœ¬å‡çº§

**å‡çº§å‰å‡†å¤‡**ï¼š
- å¤‡ä»½æ•°æ®ï¼ˆæ•°æ®åº“ã€é…ç½®æ–‡ä»¶ï¼‰
- æŸ¥çœ‹ç‰ˆæœ¬è¯´æ˜ï¼ˆCHANGELOG.mdï¼‰
- æ£€æŸ¥å‡çº§æ³¨æ„äº‹é¡¹
- åœæ­¢æœåŠ¡

**å‡çº§æ­¥éª¤**ï¼š
```bash
# 1. å¤‡ä»½æ•°æ®
scripts/backup.sh

# 2. æ‹‰å–æœ€æ–°ä»£ç 
git pull origin main

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. å‡çº§æ•°æ®åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰
python scripts/migrate_database.py

# 5. æ›´æ–°é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
cp config/config.yml.example config/config.yml.new
# æ‰‹åŠ¨åˆå¹¶é…ç½®

# 6. å¯åŠ¨æœåŠ¡
python src/api/main.py

# 7. éªŒè¯å‡çº§
curl http://localhost:8000/health
curl http://localhost:8000/api/v1/system/info
```

**ç‰ˆæœ¬å›é€€**ï¼š
```bash
# 1. åœæ­¢æœåŠ¡
python src/api/main.py stop

# 2. å›é€€ä»£ç 
git checkout <previous_version>

# 3. æ¢å¤æ•°æ®
# è§£å‹å¤‡ä»½æ–‡ä»¶

# 4. å¯åŠ¨æœåŠ¡
python src/api/main.py
```

### 9.2 æ—¥å¸¸ç»´æŠ¤

**æ¯æ—¥æ£€æŸ¥**ï¼š
- æ£€æŸ¥æœåŠ¡çŠ¶æ€ï¼š`curl http://localhost:8000/health`
- æ£€æŸ¥æ—¥å¿—æ˜¯å¦æœ‰é”™è¯¯ï¼š`grep "ERROR" data/logs/msearch.log | tail -10`
- æ£€æŸ¥ç£ç›˜ç©ºé—´ï¼š`df -h`

**æ¯å‘¨æ£€æŸ¥**ï¼š
- è¿è¡Œæ€§èƒ½æµ‹è¯•ï¼š`pytest tests/benchmark/ -v`
- æ¸…ç†æ—¥å¿—æ–‡ä»¶ï¼š`find data/logs -name "*.log.*" -mtime +7 -delete`
- æ£€æŸ¥ä»»åŠ¡æˆåŠŸç‡ï¼š`curl http://localhost:8000/api/v1/tasks/stats`

**æ¯æœˆæ£€æŸ¥**ï¼š
- å¤‡ä»½æ•°æ®ï¼š`scripts/backup.sh`
- æ£€æŸ¥æ¨¡å‹æ›´æ–°
- æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼š`rm -rf data/temp/*`
- æ£€æŸ¥ç³»ç»Ÿæ›´æ–°

### 9.3 å¸¸è§ç»´æŠ¤ä»»åŠ¡

**æ¸…ç†ä¸´æ—¶æ–‡ä»¶**ï¼š
```bash
# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -rf data/temp/*

# æ¸…ç†æ—¥å¿—æ–‡ä»¶
find data/logs -name "*.log.*" -mtime +7 -delete

# æ¸…ç†å¤‡ä»½æ–‡ä»¶
find /path/to/backup -name "*.tar.gz" -mtime +30 -delete

# æ¸…ç†ç¼“å­˜
rm -rf data/cache/preprocessing/*
```

**é‡æ–°ç´¢å¼•æ–‡ä»¶**ï¼š
```bash
# åˆ é™¤æ‰€æœ‰ç´¢å¼•ï¼ˆæ³¨æ„ï¼šè¿™ä¼šåˆ é™¤æ‰€æœ‰å‘é‡æ•°æ®ï¼‰
python scripts/clear_database_vectors.py

# é‡æ–°ç´¢å¼•
python src/api_server.py &
sleep 5
curl -X POST http://localhost:8000/api/v1/files/scan \
  -H "Content-Type: application/json" \
  -d '{"path": "/path/to/monitor"}'
```

**æ›´æ–°æ¨¡å‹**ï¼š
```bash
# æ£€æŸ¥æ¨¡å‹çŠ¶æ€
python scripts/setup_models.py check

# å¼ºåˆ¶é‡æ–°ä¸‹è½½
python scripts/setup_models.py setup --force

# é‡å¯æœåŠ¡
bash scripts/run.sh
```

**æ•°æ®åº“ç»´æŠ¤**ï¼š
```bash
# å¤‡ä»½æ•°æ®åº“
cp data/database/sqlite/msearch.db data/database/sqlite/msearch.db.backup

# æ¸…ç†å‘é‡æ•°æ®åº“
rm -rf data/database/lancedb/unified_vectors

# é‡æ–°åˆå§‹åŒ–
python src/api_server.py
```

---

## é™„å½•

### A.1 é…ç½®å‚æ•°å‚è€ƒ

**å®Œæ•´é…ç½®æ–‡ä»¶**ï¼š`config/config.yml.example`

**å¸¸ç”¨é…ç½®å‚æ•°**ï¼š
| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | æ¨èå€¼ |
|------|------|-------|-------|
| `models.[é…ç½®é©±åŠ¨æ¨¡å‹].batch_size` | å›¾åƒ/è§†é¢‘æ¨¡å‹æ‰¹å¤„ç†å¤§å° | 16 | 8-32 |
| `models.[é…ç½®é©±åŠ¨æ¨¡å‹].precision` | æ¨¡å‹ç²¾åº¦ | float16 | float16/float32 |
| `models.[é…ç½®é©±åŠ¨æ¨¡å‹].device` | æ¨¡å‹è®¾å¤‡ | cuda | cuda/cpu |
| `models.[é…ç½®é©±åŠ¨æ¨¡å‹].batch_size` | éŸ³é¢‘æ¨¡å‹æ‰¹å¤„ç†å¤§å° | 8 | 4-16 |
| `performance.video_processing.frame_interval` | è§†é¢‘é‡‡æ ·é—´éš” | 10 | 5-20 |
| `performance.video_processing.target_fps` | è§†é¢‘ç›®æ ‡å¸§ç‡ | 2 | 1-5 |
| `performance.video_processing.max_segments_per_video` | æœ€å¤§åˆ†æ®µæ•° | 100 | 50-200 |
| `task_scheduler.max_workers` | ä»»åŠ¡è°ƒåº¦å™¨å·¥ä½œçº¿ç¨‹æ•° | 4 | 2-8 |
| `api.port` | API ç«¯å£ | 8000 | 8000-8080 |
| `logging.level` | æ—¥å¿—çº§åˆ« | INFO | DEBUG/INFO/WARNING |

### A.2 å‘½ä»¤å‚è€ƒ

**å¸¸ç”¨å‘½ä»¤**ï¼š
```bash
# å®‰è£…éƒ¨ç½²
bash scripts/install.sh              # ä¸€é”®å®‰è£…
bash scripts/run.sh                  # ä¸€é”®å¯åŠ¨

# æ¨¡å‹ç®¡ç†
python scripts/setup_models.py check # æ£€æŸ¥æ¨¡å‹
python scripts/setup_models.py setup # ä¸‹è½½æ¨¡å‹
python scripts/setup_models.py clear # æ¸…é™¤æ¨¡å‹

# æœåŠ¡ç®¡ç†
bash scripts/run.sh                  # å¯åŠ¨æœåŠ¡
pkill -f "python src/api_server.py"  # åœæ­¢æœåŠ¡

# æ•°æ®åº“ç®¡ç†
python scripts/clear_database_vectors.py  # æ¸…é™¤å‘é‡æ•°æ®
cp data/database/sqlite/msearch.db data/database/sqlite/msearch.db.backup  # å¤‡ä»½æ•°æ®åº“

# æ—¥å¿—æŸ¥çœ‹
tail -f data/logs/msearch.log        # æŸ¥çœ‹ä¸»æ—¥å¿—
tail -f data/logs/api.log            # æŸ¥çœ‹APIæ—¥å¿—

# æµ‹è¯•
pytest tests/unit/ -v                # è¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/integration/ -v         # è¿è¡Œé›†æˆæµ‹è¯•
```

**APIå‘½ä»¤**ï¼š
```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# ç³»ç»Ÿä¿¡æ¯
curl http://localhost:8000/api/v1/system/info

# æ¨¡å‹ä¿¡æ¯
curl http://localhost:8000/api/v1/models/info

# æ–‡æœ¬æœç´¢
curl -X POST http://localhost:8000/api/v1/search \
  -H "Content-Type: application/json" \
  -d '{"query": "æµ‹è¯•æœç´¢", "top_k": 10}'

# å›¾åƒæœç´¢
curl -X POST http://localhost:8000/api/v1/search/image \
  -F "image=@/path/to/image.jpg" \
  -F "top_k=10"

# éŸ³é¢‘æœç´¢
curl -X POST http://localhost:8000/api/v1/search/audio \
  -F "audio=@/path/to/audio.mp3" \
  -F "top_k=10"

# æ–‡ä»¶æ‰«æ
curl -X POST http://localhost:8000/api/v1/files/scan \
  -H "Content-Type: application/json" \
  -d '{"path": "/path/to/monitor"}'
```

### A.3 æ•…éšœæ’æŸ¥æµç¨‹å›¾

```
ç”¨æˆ·æŠ¥å‘Šé—®é¢˜
    â†“
æ”¶é›†ä¿¡æ¯ï¼ˆæ—¥å¿—ã€ç³»ç»ŸçŠ¶æ€ã€é…ç½®ï¼‰
    â†“
æŸ¥çœ‹å¸¸è§é—®é¢˜
    â†“
æ˜¯å¦æ‰¾åˆ°è§£å†³æ–¹æ¡ˆï¼Ÿ
    â†“ æ˜¯
å°è¯•ä¿®å¤
    â†“
éªŒè¯ä¿®å¤
    â†“
é—®é¢˜è§£å†³ï¼Ÿ
    â†“ æ˜¯
è®°å½•é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
    â†“
ç»“æŸ
    
    â†“ å¦ï¼ˆå¸¸è§é—®é¢˜æœªæ‰¾åˆ°ï¼‰
æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
    â†“
ä½¿ç”¨è¯Šæ–­å·¥å…·
    â†“
å®šä½é—®é¢˜
    â†“
å°è¯•ä¿®å¤
    â†“
éªŒè¯ä¿®å¤
    â†“
é—®é¢˜è§£å†³ï¼Ÿ
    â†“ æ˜¯
è®°å½•é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
    â†“
ç»“æŸ
    
    â†“ å¦
è”ç³»æŠ€æœ¯æ”¯æŒ
    â†“
æä¾›è¯¦ç»†ä¿¡æ¯
    â†“
ç­‰å¾…æ”¯æŒ
```

### A.4 æ”¯æŒä¸åé¦ˆ

**è·å–å¸®åŠ©**ï¼š
- **å¿«é€Ÿå¼€å§‹**ï¼š[QUICKSTART.md](../QUICKSTART.md)
- **å®Œæ•´æ–‡æ¡£**ï¼šdocs/ ç›®å½•ä¸‹çš„æ–‡æ¡£
- **APIæ–‡æ¡£**ï¼šhttp://localhost:8000/docsï¼ˆå¯åŠ¨åè®¿é—®ï¼‰
- **é—®é¢˜è·Ÿè¸ª**ï¼šGitHub Issues

**åé¦ˆé—®é¢˜**ï¼š
- æä¾›è¯¦ç»†çš„é—®é¢˜æè¿°
- æä¾›é”™è¯¯æ—¥å¿—ï¼ˆ`data/logs/msearch.log`ï¼‰
- æä¾›ç³»ç»Ÿä¿¡æ¯ï¼ˆCPUã€å†…å­˜ã€GPUã€æ“ä½œç³»ç»Ÿï¼‰
- æä¾›å¤ç°æ­¥éª¤
- æä¾›é¢„æœŸç»“æœå’Œå®é™…ç»“æœ

**å¸¸è§é—®é¢˜**ï¼š
1. **æ¨¡å‹ä¸‹è½½å¤±è´¥**ï¼šä½¿ç”¨å›½å†…é•œåƒ `export HF_ENDPOINT=https://hf-mirror.com`
2. **CUDAä¸å¯ç”¨**ï¼šæ£€æŸ¥NVIDIAé©±åŠ¨å’ŒCUDAå®‰è£…
3. **ç«¯å£è¢«å ç”¨**ï¼šä¿®æ”¹ `config/config.yml` ä¸­çš„ç«¯å£é…ç½®
4. **å†…å­˜ä¸è¶³**ï¼šé™ä½ `batch_size` æˆ–ä½¿ç”¨CPUæ¨ç†
5. **æ£€ç´¢ç»“æœä¸ºç©º**ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å·²ç´¢å¼•çš„æ–‡ä»¶

**ç¦»çº¿æ¨¡å¼**ï¼š
```bash
# è®¾ç½®ç¦»çº¿ç¯å¢ƒå˜é‡
export TRANSFORMERS_OFFLINE=1
export HF_DATASETS_OFFLINE=1
export HF_HUB_OFFLINE=1
export HF_HOME="data/models"

# å¯åŠ¨ç¦»çº¿æ¨¡å¼
bash scripts/run_offline.sh
```

---

**Â© 2026 msearch æŠ€æœ¯å›¢é˜Ÿ**  
**æœ¬æ–‡æ¡£å—å›¢é˜Ÿå†…éƒ¨ä¿å¯†åè®®ä¿æŠ¤**

---

## å˜æ›´æ—¥å¿—

### v2.0 (2026-01-23)
- æ–°å¢å¿«é€Ÿå®‰è£…å’Œå¯åŠ¨è„šæœ¬
- æ–°å¢æ¨¡å‹ç®¡ç†å’Œæ£€æŸ¥åŠŸèƒ½
- æ–°å¢PySide6æ¡Œé¢UI
- æ–°å¢ç¦»çº¿æ¨¡å¼æ”¯æŒ
- ä¼˜åŒ–æ¨¡å‹ä¸‹è½½é€»è¾‘ï¼ˆæ”¯æŒå›½å†…é•œåƒï¼‰
- ä¼˜åŒ–é…ç½®æ–‡ä»¶ç»“æ„

### v1.0 (2026-01-19)
- åˆå§‹ç‰ˆæœ¬
- å®Œæ•´çš„éƒ¨ç½²å’Œè¿ç»´æ–‡æ¡£